{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sochastic Gradient Descent with Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sls\n",
    "import smb\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs to train for\n",
    "epochs = 20\n",
    "\n",
    "# Dataset-Model\n",
    "TrainOptions = {1:('mnist', 'mlp'), \n",
    "                2:('cifar10', 'resnet34_10'), \n",
    "                3:('cifar10', 'densenet10'), \n",
    "                4:('cifar100', 'resnet34_100'), \n",
    "                5:('cifar100', 'densenet10')\n",
    "                }\n",
    "dataset_name, model_name = TrainOptions[1]\n",
    "\n",
    "\n",
    "# Batch Size\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "use_GPU = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "\n",
    "# Get Dataset\n",
    "train_set, test_set, train_loader = get_dataset(dataset_name, batch_size)\n",
    "n_batches_per_epoch = len(train_loader)\n",
    "\n",
    " \n",
    "# Get Model\n",
    "model = get_model(model_name)\n",
    "if use_GPU:\n",
    "    model.cuda()\n",
    "    \n",
    "opt_out_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with SMB optimizer\n",
    "\n",
    "SMB optimizer requires a closure function. You can its form below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to train with SMB optimizer: For 20 epochs\n",
      "Epoch: 1   -   Training Loss: 0.534047  -  Test Accuracy: 0.8433  -  Time: 14.74\n",
      "Epoch: 2   -   Training Loss: 0.287748  -  Test Accuracy: 0.9141  -  Time: 14.77\n",
      "Epoch: 3   -   Training Loss: 0.262469  -  Test Accuracy: 0.919  -  Time: 14.39\n",
      "Epoch: 4   -   Training Loss: 0.330394  -  Test Accuracy: 0.9036  -  Time: 14.07\n",
      "Epoch: 5   -   Training Loss: 0.199763  -  Test Accuracy: 0.9392  -  Time: 13.72\n",
      "Epoch: 6   -   Training Loss: 0.224365  -  Test Accuracy: 0.9315  -  Time: 13.63\n",
      "Epoch: 7   -   Training Loss: 0.196397  -  Test Accuracy: 0.9393  -  Time: 13.57\n",
      "Epoch: 8   -   Training Loss: 0.185515  -  Test Accuracy: 0.9379  -  Time: 13.47\n",
      "Epoch: 9   -   Training Loss: 0.122668  -  Test Accuracy: 0.9562  -  Time: 13.33\n",
      "Epoch: 10   -   Training Loss: 0.117434  -  Test Accuracy: 0.9605  -  Time: 13.21\n",
      "Epoch: 11   -   Training Loss: 0.149203  -  Test Accuracy: 0.9499  -  Time: 13.39\n",
      "Epoch: 12   -   Training Loss: 0.115166  -  Test Accuracy: 0.9572  -  Time: 13.9\n",
      "Epoch: 13   -   Training Loss: 0.158789  -  Test Accuracy: 0.9476  -  Time: 13.42\n",
      "Epoch: 14   -   Training Loss: 0.115762  -  Test Accuracy: 0.9572  -  Time: 13.45\n",
      "Epoch: 15   -   Training Loss: 0.147634  -  Test Accuracy: 0.9476  -  Time: 13.14\n",
      "Epoch: 16   -   Training Loss: 0.166005  -  Test Accuracy: 0.9432  -  Time: 13.11\n",
      "Epoch: 17   -   Training Loss: 0.114849  -  Test Accuracy: 0.9513  -  Time: 13.27\n",
      "Epoch: 18   -   Training Loss: 0.143652  -  Test Accuracy: 0.9513  -  Time: 13.23\n",
      "Epoch: 19   -   Training Loss: 0.098448  -  Test Accuracy: 0.9606  -  Time: 13.34\n",
      "Epoch: 20   -   Training Loss: 0.139279  -  Test Accuracy: 0.9522  -  Time: 13.22\n"
     ]
    }
   ],
   "source": [
    "independent_batch = False\n",
    "autoschedule = False\n",
    "\n",
    "opt_out = {}\n",
    "\n",
    "if independent_batch:\n",
    "    opt_out.update({'name':'SMBi'})\n",
    "else:\n",
    "    opt_out.update({'name':'SMB'})\n",
    "\n",
    "opt_out.update({'independent_batch':independent_batch, \n",
    "           'autoschedule':autoschedule, \n",
    "           'gamma':0.05, \n",
    "           'beta':0.9, \n",
    "           'lr':1, \n",
    "           'c':0.1, \n",
    "           'eta':0.99, \n",
    "           'data':dataset_name, \n",
    "           'model':model_name, \n",
    "           })\n",
    " \n",
    " \n",
    "# loss function\n",
    "criterion = softmax_loss\n",
    " \n",
    "optimizer = smb.SMB(model.parameters(), \n",
    "                lr=opt_out['lr'], \n",
    "                c=opt_out['c'], \n",
    "                eta=opt_out['eta'], \n",
    "                independent_batch=opt_out['independent_batch'], \n",
    "                autoschedule=opt_out['autoschedule'],\n",
    "                n_batches_per_epoch=n_batches_per_epoch)\n",
    "\n",
    "print('\\n' + 'Starting to train with {} optimizer: For {} epochs'.format(opt_out['name'], epochs))\n",
    "\n",
    "train_loss_list = []\n",
    "test_acc_list = []\n",
    "run_time_list = []\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    step_type = []\n",
    "        \n",
    "    begin = time.time()\n",
    "    \n",
    "    # training steps\n",
    "    model.train()\n",
    "    \n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # moves tensors to GPU if available\n",
    "        if use_GPU:\n",
    "            data, target = data.cuda(), target.cuda() \n",
    "            \n",
    "        # create loss closure for smb algorithm\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model, data, target)\n",
    "            return loss\n",
    "        \n",
    "        # forward pass\n",
    "        loss = optimizer.step(closure=closure)\n",
    "        \n",
    "    end = time.time()\n",
    "        \n",
    "    train_loss = compute_loss(model, train_set)\n",
    "    test_acc = compute_accuracy(model, test_set)\n",
    "        \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    run_time_list.append(end-begin)\n",
    "        \n",
    "    # Display loss statistics\n",
    "    print(f'Epoch: {epoch}   -   Training Loss: {round(train_loss, 6)}  -  Test Accuracy: {round(test_acc, 6)}  -  Time: {round(end-begin, 2)}')\n",
    "\n",
    "    \n",
    "opt_out.update({'train_loss':train_loss_list,\n",
    "                 'test_acc':test_acc_list,\n",
    "                 'run_time':run_time_list,\n",
    "                })\n",
    "\n",
    "opt_out_list.append(opt_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with SLS optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to train with SLS optimizer: For 20 epochs\n",
      "Epoch: 1   -   Training Loss: 0.053302  -  Test Accuracy: 0.9694  -  Time: 12.86\n",
      "Epoch: 2   -   Training Loss: 0.038561  -  Test Accuracy: 0.971  -  Time: 12.79\n",
      "Epoch: 3   -   Training Loss: 0.030447  -  Test Accuracy: 0.9735  -  Time: 12.94\n",
      "Epoch: 4   -   Training Loss: 0.031635  -  Test Accuracy: 0.973  -  Time: 12.97\n",
      "Epoch: 5   -   Training Loss: 0.020154  -  Test Accuracy: 0.9745  -  Time: 12.89\n",
      "Epoch: 6   -   Training Loss: 0.017805  -  Test Accuracy: 0.9736  -  Time: 12.81\n",
      "Epoch: 7   -   Training Loss: 0.017402  -  Test Accuracy: 0.9744  -  Time: 12.82\n",
      "Epoch: 8   -   Training Loss: 0.013552  -  Test Accuracy: 0.9749  -  Time: 12.89\n",
      "Epoch: 9   -   Training Loss: 0.014434  -  Test Accuracy: 0.9745  -  Time: 12.85\n",
      "Epoch: 10   -   Training Loss: 0.011622  -  Test Accuracy: 0.9743  -  Time: 13.12\n",
      "Epoch: 11   -   Training Loss: 0.008599  -  Test Accuracy: 0.9743  -  Time: 12.81\n",
      "Epoch: 12   -   Training Loss: 0.007645  -  Test Accuracy: 0.9751  -  Time: 12.91\n",
      "Epoch: 13   -   Training Loss: 0.007209  -  Test Accuracy: 0.9738  -  Time: 12.91\n",
      "Epoch: 14   -   Training Loss: 0.005265  -  Test Accuracy: 0.9755  -  Time: 12.94\n",
      "Epoch: 15   -   Training Loss: 0.005666  -  Test Accuracy: 0.9748  -  Time: 13.13\n"
     ]
    }
   ],
   "source": [
    "opt_out = {'name':'SLS', \n",
    "           'lr':1, \n",
    "           'c':0.1, \n",
    "           'reset_option':1, \n",
    "           'data':dataset_name, \n",
    "           'model':model_name, \n",
    "           }\n",
    "\n",
    " \n",
    "# loss function\n",
    "criterion = softmax_loss\n",
    "\n",
    "\n",
    "optimizer = sls.Sls(model.parameters(), \n",
    "                    init_step_size=opt_out['lr'], \n",
    "                    reset_option=opt_out['reset_option'], \n",
    "                    c=opt_out['c'], \n",
    "                    n_batches_per_epoch=n_batches_per_epoch\n",
    "                   )\n",
    "\n",
    "print('\\n' + 'Starting to train with {} optimizer: For {} epochs'.format(opt_out['name'], epochs))\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "train_iter_loss_list = []\n",
    "test_acc_list = []\n",
    "run_time_list = []\n",
    "\n",
    "loss = None\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "        \n",
    "    begin = time.time()\n",
    "    \n",
    "    # training steps\n",
    "    model.train()\n",
    "    \n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # moves tensors to GPU\n",
    "        if use_GPU:\n",
    "            data, target = data.cuda(), target.cuda() \n",
    "            \n",
    "        # create loss closure for sls algorithm\n",
    "        closure = lambda :  criterion(model, data, target)  \n",
    "        # clears gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = optimizer.step(closure=closure)\n",
    "        \n",
    "        train_iter_loss_list.append(loss.item())\n",
    "        \n",
    "    end = time.time()\n",
    "    \n",
    "    train_loss = compute_loss(model, train_set)\n",
    "    test_acc = compute_accuracy(model, test_set)\n",
    "        \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    run_time_list.append(end-begin)\n",
    "        \n",
    "    # Display loss statistics\n",
    "    print(f'Epoch: {epoch}   -   Training Loss: {round(train_loss, 6)}  -  Test Accuracy: {round(test_acc, 6)}  -  Time: {round(end-begin, 2)}')\n",
    "    \n",
    "    #print(epoch, end=' ')\n",
    "    \n",
    "opt_out.update({'train_loss':train_loss_list,\n",
    "                 'test_acc':test_acc_list,\n",
    "                 'run_time':run_time_list,\n",
    "                 'train_iter_loss':train_iter_loss_list,\n",
    "                })\n",
    "\n",
    "opt_out_list.append(opt_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with ADAM optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_out = {'name':'Adam', \n",
    "           'lr':0.001, \n",
    "           'data':dataset_name, \n",
    "           'model':model_name,\n",
    "           } \n",
    " \n",
    "# loss function\n",
    "criterion = softmax_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = opt_out['lr'])\n",
    "\n",
    "\n",
    "print('\\n' + 'Starting to train with {} optimizer: For {} epochs'.format(opt_out['name'], epochs))\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "test_acc_list = []\n",
    "run_time_list = []\n",
    "    \n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "        \n",
    "    begin = time.time()\n",
    "\n",
    "    # training steps\n",
    "    model.train()\n",
    "    for batch_index, (data, target) in enumerate(train_loader):            \n",
    "            \n",
    "        # moves tensors to GPU\n",
    "        if use_GPU:\n",
    "            data, target = data.cuda(), target.cuda()     \n",
    "        # clears gradients\n",
    "        optimizer.zero_grad()\n",
    "        # loss in batch\n",
    "        loss = criterion(model, data, target)\n",
    "        # backward pass for loss gradient\n",
    "        loss.backward()\n",
    "            \n",
    "            \n",
    "        # update paremeters\n",
    "        optimizer.step()\n",
    "            \n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss = compute_loss(model, train_set)\n",
    "    test_acc = compute_accuracy(model, test_set)\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    run_time_list.append(end-begin)\n",
    "        \n",
    "    # Display loss statistics\n",
    "    print(f'Epoch: {epoch}   -   Training Loss: {round(train_loss, 6)}   -   Test Accuracy: {round(test_acc, 6)}  -  Time: {round(end-begin, 2)}')\n",
    "\n",
    "\n",
    "opt_out.update({'train_loss':train_loss_list,\n",
    "                 'test_acc':test_acc_list,\n",
    "                 'run_time':run_time_list,\n",
    "                })\n",
    "\n",
    "opt_out_list.append(opt_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_out = {'name':'SGD', \n",
    "           'lr':0.1, \n",
    "           'data':dataset_name, \n",
    "           'model':model_name,\n",
    "           }\n",
    " \n",
    "# loss function\n",
    "criterion = softmax_loss\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = opt_out['lr'])\n",
    "\n",
    "print('\\n' + 'Starting to train with {} optimizer: For {} epochs'.format(opt_out['name'], epochs))\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "test_acc_list = []\n",
    "run_time_list = []\n",
    "    \n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "        \n",
    "    begin = time.time()\n",
    "\n",
    "    # training steps\n",
    "    model.train()\n",
    "    for batch_index, (data, target) in enumerate(train_loader):            \n",
    "            \n",
    "        # moves tensors to GPU\n",
    "        if use_GPU:\n",
    "            data, target = data.cuda(), target.cuda()     \n",
    "        # clears gradients\n",
    "        optimizer.zero_grad()\n",
    "        # loss in batch\n",
    "        loss = criterion(model, data, target)\n",
    "        # backward pass for loss gradient\n",
    "        loss.backward()\n",
    "            \n",
    "            \n",
    "        # update paremeters\n",
    "        optimizer.step()\n",
    "            \n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss = compute_loss(model, train_set)\n",
    "    test_acc = compute_accuracy(model, test_set)\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    run_time_list.append(end-begin)\n",
    "        \n",
    "    # Display loss statistics\n",
    "    print(f'Epoch: {epoch}   -   Training Loss: {round(train_loss, 6)}   -   Test Accuracy: {round(test_acc, 6)}  -  Time: {round(end-begin, 2)}')\n",
    "\n",
    "\n",
    "opt_out.update({'train_loss':train_loss_list,\n",
    "                 'test_acc':test_acc_list,\n",
    "                 'run_time':run_time_list,\n",
    "                })\n",
    "\n",
    "opt_out_list.append(opt_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss_acc_graph(opt_out_list, \"{}-{}\".format(dataset_name, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_time_graph(opt_out_list, \"{}-{}\".format(dataset_name, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
